{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-24T15:49:55.272103Z",
     "iopub.status.busy": "2025-01-24T15:49:55.271852Z",
     "iopub.status.idle": "2025-01-24T15:50:02.498026Z",
     "shell.execute_reply": "2025-01-24T15:50:02.497169Z",
     "shell.execute_reply.started": "2025-01-24T15:49:55.272073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:02.502336Z",
     "iopub.status.busy": "2025-01-24T15:50:02.502114Z",
     "iopub.status.idle": "2025-01-24T15:50:02.689879Z",
     "shell.execute_reply": "2025-01-24T15:50:02.689242Z",
     "shell.execute_reply.started": "2025-01-24T15:50:02.502318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# wandb_api_key = user_secrets.get_secret(\"wandb-key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:02.690995Z",
     "iopub.status.busy": "2025-01-24T15:50:02.690703Z",
     "iopub.status.idle": "2025-01-24T15:50:09.287018Z",
     "shell.execute_reply": "2025-01-24T15:50:09.286145Z",
     "shell.execute_reply.started": "2025-01-24T15:50:02.690965Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mankittriescoding\u001b[0m (\u001b[33mankittriescoding-indian-institute-of-technology-kharagpur\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb.login(key=wandb_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:09.288828Z",
     "iopub.status.busy": "2025-01-24T15:50:09.288035Z",
     "iopub.status.idle": "2025-01-24T15:50:15.543161Z",
     "shell.execute_reply": "2025-01-24T15:50:15.542430Z",
     "shell.execute_reply.started": "2025-01-24T15:50:09.288790Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250124_155009-rnld8plc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ankittriescoding-indian-institute-of-technology-kharagpur/lora-bert-finetune/runs/rnld8plc' target=\"_blank\">decent-frost-3</a></strong> to <a href='https://wandb.ai/ankittriescoding-indian-institute-of-technology-kharagpur/lora-bert-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ankittriescoding-indian-institute-of-technology-kharagpur/lora-bert-finetune' target=\"_blank\">https://wandb.ai/ankittriescoding-indian-institute-of-technology-kharagpur/lora-bert-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ankittriescoding-indian-institute-of-technology-kharagpur/lora-bert-finetune/runs/rnld8plc' target=\"_blank\">https://wandb.ai/ankittriescoding-indian-institute-of-technology-kharagpur/lora-bert-finetune/runs/rnld8plc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"lora-bert-finetune\",\n",
    "    config={\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"epochs\": 4,\n",
    "        \"batch_size\": 16,\n",
    "        \"max_len\": 512,\n",
    "        \"lora_r\": 8,\n",
    "        \"lora_alpha\": 16,\n",
    "        \"lora_dropout\": 0.1,\n",
    "    },\n",
    ")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:15.544286Z",
     "iopub.status.busy": "2025-01-24T15:50:15.543968Z",
     "iopub.status.idle": "2025-01-24T15:50:15.550199Z",
     "shell.execute_reply": "2025-01-24T15:50:15.549394Z",
     "shell.execute_reply.started": "2025-01-24T15:50:15.544254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.smiles = dataframe[\"smiles\"].values\n",
    "        self.labels = dataframe[\"HIV_active\"].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles) \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smiles = self.smiles[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            smiles,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:15.551290Z",
     "iopub.status.busy": "2025-01-24T15:50:15.551027Z",
     "iopub.status.idle": "2025-01-24T15:50:15.566334Z",
     "shell.execute_reply": "2025-01-24T15:50:15.565431Z",
     "shell.execute_reply.started": "2025-01-24T15:50:15.551269Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-uncased\", num_labels=2\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:15.569175Z",
     "iopub.status.busy": "2025-01-24T15:50:15.568941Z",
     "iopub.status.idle": "2025-01-24T15:50:15.587736Z",
     "shell.execute_reply": "2025-01-24T15:50:15.586906Z",
     "shell.execute_reply.started": "2025-01-24T15:50:15.569156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:15.589982Z",
     "iopub.status.busy": "2025-01-24T15:50:15.589779Z",
     "iopub.status.idle": "2025-01-24T15:50:15.605202Z",
     "shell.execute_reply": "2025-01-24T15:50:15.604446Z",
     "shell.execute_reply.started": "2025-01-24T15:50:15.589965Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(device, model, train_loader, optimizer, epoch, checkpoint_dir):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    train_loader = tqdm(train_loader, desc=\"Training\", leave=True)\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loader.set_postfix(loss=loss.item())\n",
    "        wandb.log({\"batch_loss\": loss.item()})\n",
    "\n",
    "        if (batch_idx + 1) % 500 == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch{epoch}.pt\")\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"batch_idx\": batch_idx,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            }, checkpoint_path)\n",
    "            print(f\"***Checkpoint saved at {checkpoint_path}***\")\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def train_model(device, model, epochs, train_loader, optimizer, checkpoint_path, train_ckpt=False):\n",
    "    start_epoch = 0\n",
    "\n",
    "    if train_ckpt:\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        print(f\"***Resumed training from epoch {start_epoch}***\")\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        train_loss = train_epoch(device, model, train_loader, optimizer, epoch, checkpoint_path)\n",
    "        wandb.log({\"epoch_train_loss\": train_loss})\n",
    "        print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "        epoch_checkpoint_path = os.path.join(checkpoint_path, f\"checkpoint_epoch{epoch}_complete.pt\")\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        }, epoch_checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {epoch_checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:37:03.868972Z",
     "iopub.status.busy": "2025-01-24T17:37:03.868622Z",
     "iopub.status.idle": "2025-01-24T17:37:03.876424Z",
     "shell.execute_reply": "2025-01-24T17:37:03.875559Z",
     "shell.execute_reply.started": "2025-01-24T17:37:03.868949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def eval_model(device, model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    test_loader = tqdm(test_loader, desc=\"Evaluating\", leave=True)\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"]\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels.numpy())\n",
    "\n",
    "    report = classification_report(true_labels, predictions, output_dict=True)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"eval_accuracy\": report[\"accuracy\"],\n",
    "        \"eval_precision_macro\": report[\"macro avg\"][\"precision\"],\n",
    "        \"eval_recall_macro\": report[\"macro avg\"][\"recall\"],\n",
    "        \"eval_f1_macro\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"eval_precision_weighted\": report[\"weighted avg\"][\"precision\"],\n",
    "        \"eval_recall_weighted\": report[\"weighted avg\"][\"recall\"],\n",
    "        \"eval_f1_weighted\": report[\"weighted avg\"][\"f1-score\"]\n",
    "    })\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:15.626084Z",
     "iopub.status.busy": "2025-01-24T15:50:15.625770Z",
     "iopub.status.idle": "2025-01-24T15:50:15.639684Z",
     "shell.execute_reply": "2025-01-24T15:50:15.638949Z",
     "shell.execute_reply.started": "2025-01-24T15:50:15.626035Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TRAIN = os.path.join(\"../input/moleculenet-hiv-split/train.csv\")\n",
    "TEST = os.path.join(\"../input/moleculenet-hiv-split/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:15.640562Z",
     "iopub.status.busy": "2025-01-24T15:50:15.640383Z",
     "iopub.status.idle": "2025-01-24T15:50:15.656265Z",
     "shell.execute_reply": "2025-01-24T15:50:15.655452Z",
     "shell.execute_reply.started": "2025-01-24T15:50:15.640545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"/kaggle/working/training/\"):\n",
    "    os.makedirs(\"/kaggle/working/training/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:15.657362Z",
     "iopub.status.busy": "2025-01-24T15:50:15.657153Z",
     "iopub.status.idle": "2025-01-24T15:50:15.746971Z",
     "shell.execute_reply": "2025-01-24T15:50:15.746271Z",
     "shell.execute_reply.started": "2025-01-24T15:50:15.657343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(TRAIN)\n",
    "test_data = pd.read_csv(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:15.748095Z",
     "iopub.status.busy": "2025-01-24T15:50:15.747864Z",
     "iopub.status.idle": "2025-01-24T15:50:19.891669Z",
     "shell.execute_reply": "2025-01-24T15:50:19.890681Z",
     "shell.execute_reply.started": "2025-01-24T15:50:15.748075Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f8886588744fef928d002cf14fa1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0714b22b8744e198d79d3eb4f85b681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e732eba7aaa4947bb52d418501f2816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9f5b1c7d6446b7b399662ab56a069c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106b2a75937945939a7b79a61c8d6f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "max_len = 512\n",
    "base_model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:19.892936Z",
     "iopub.status.busy": "2025-01-24T15:50:19.892609Z",
     "iopub.status.idle": "2025-01-24T15:50:20.279526Z",
     "shell.execute_reply": "2025-01-24T15:50:20.278571Z",
     "shell.execute_reply.started": "2025-01-24T15:50:19.892903Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 296,450 || all params: 109,780,228 || trainable%: 0.2700\n"
     ]
    }
   ],
   "source": [
    "lora_model = get_peft_model(base_model, config)\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:20.280687Z",
     "iopub.status.busy": "2025-01-24T15:50:20.280441Z",
     "iopub.status.idle": "2025-01-24T15:50:20.290351Z",
     "shell.execute_reply": "2025-01-24T15:50:20.289513Z",
     "shell.execute_reply.started": "2025-01-24T15:50:20.280663Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = SMILESDataset(train_data, tokenizer, max_len)\n",
    "test_dataset = SMILESDataset(test_data, tokenizer, max_len)\n",
    "\n",
    "del train_data, test_data\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "del train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:20.291442Z",
     "iopub.status.busy": "2025-01-24T15:50:20.291159Z",
     "iopub.status.idle": "2025-01-24T15:50:20.719449Z",
     "shell.execute_reply": "2025-01-24T15:50:20.718253Z",
     "shell.execute_reply.started": "2025-01-24T15:50:20.291417Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Using cuda***\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lora_model.to(device)\n",
    "wandb.watch(lora_model)\n",
    "print(f\"***Using {device}***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:20.720514Z",
     "iopub.status.busy": "2025-01-24T15:50:20.720294Z",
     "iopub.status.idle": "2025-01-24T15:50:20.726457Z",
     "shell.execute_reply": "2025-01-24T15:50:20.725530Z",
     "shell.execute_reply.started": "2025-01-24T15:50:20.720494Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(lora_model.parameters(), lr=5e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:50:20.727712Z",
     "iopub.status.busy": "2025-01-24T15:50:20.727416Z",
     "iopub.status.idle": "2025-01-24T15:50:20.741608Z",
     "shell.execute_reply": "2025-01-24T15:50:20.740814Z",
     "shell.execute_reply.started": "2025-01-24T15:50:20.727681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:29:05.777723Z",
     "iopub.status.busy": "2025-01-24T17:29:05.777406Z",
     "iopub.status.idle": "2025-01-24T17:29:06.134888Z",
     "shell.execute_reply": "2025-01-24T17:29:06.134024Z",
     "shell.execute_reply.started": "2025-01-24T17:29:05.777700Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/training/tokenizer_config.json',\n",
       " '/kaggle/working/training/special_tokens_map.json',\n",
       " '/kaggle/working/training/vocab.txt',\n",
       " '/kaggle/working/training/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(device, lora_model, epochs, train_loader, optimizer, \"/kaggle/working/training/\")\n",
    "lora_model.save_pretrained(\"/kaggle/working/training/\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working/training/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:29:09.871529Z",
     "iopub.status.busy": "2025-01-24T17:29:09.871159Z",
     "iopub.status.idle": "2025-01-24T17:29:09.876500Z",
     "shell.execute_reply": "2025-01-24T17:29:09.875427Z",
     "shell.execute_reply.started": "2025-01-24T17:29:09.871496Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# run only if you want to start from a checkpoint\n",
    "# train_model(device, lora_model, epochs, train_loader, optimizer, train_ckpt=False, \"/kaggle/working/training/checkpoint_epoch{write}_{can be complete.pt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:29:10.995847Z",
     "iopub.status.busy": "2025-01-24T17:29:10.995558Z",
     "iopub.status.idle": "2025-01-24T17:29:11.009896Z",
     "shell.execute_reply": "2025-01-24T17:29:11.009026Z",
     "shell.execute_reply.started": "2025-01-24T17:29:10.995826Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 14 files into the W&B run directory, call wandb.save again to sync new files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/kaggle/working/wandb/run-20250124_155009-rnld8plc/files/training/README.md',\n",
       " '/kaggle/working/wandb/run-20250124_155009-rnld8plc/files/training/checkpoint_epoch2_complete.pt',\n",
       " '/kaggle/working/wandb/run-20250124_155009-rnld8plc/files/training/checkpoint_epoch3.pt',\n",
       " '/kaggle/working/wandb/run-20250124_155009-rnld8plc/files/training/checkpoint_epoch0_complete.pt',\n",
       " '/kaggle/working/wandb/run-20250124_155009-rnld8plc/files/training/adapter_config.json',\n",
       " '/kaggle/working/wandb/run-20250124_155009-rnld8plc/files/training/checkpoint_epoch2.pt',\n",
       " '/kaggle/working/wandb/run-20250124_155009-rnld8plc/files/training/tokenizer_config.json',\n",
       " '/kaggle/working/wandb/run-20250124_155009-rnld8plc/files/training/checkpoint_epoch1_complete.pt',\n",
       " '/kaggle/working/wandb/run-20250124_155009-rnld8plc/files/training/special_tokens_map.json',\n",
       " '/kaggle/working/wandb/run-20250124_155009-rnld8plc/files/training/checkpoint_epoch3_complete.pt',\n",
       " '/kaggle/working/wandb/run-20250124_155009-rnld8plc/files/training/adapter_model.safetensors',\n",
       " '/kaggle/working/wandb/run-20250124_155009-rnld8plc/files/training/vocab.txt',\n",
       " '/kaggle/working/wandb/run-20250124_155009-rnld8plc/files/training/checkpoint_epoch1.pt',\n",
       " '/kaggle/working/wandb/run-20250124_155009-rnld8plc/files/training/checkpoint_epoch0.pt']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.save(os.path.join(\"/kaggle/working/training/\", \"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:37:07.578614Z",
     "iopub.status.busy": "2025-01-24T17:37:07.578296Z",
     "iopub.status.idle": "2025-01-24T17:38:59.941146Z",
     "shell.execute_reply": "2025-01-24T17:38:59.939929Z",
     "shell.execute_reply.started": "2025-01-24T17:37:07.578589Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 415/415 [01:52<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9773036768043577, 'recall': 0.9987629503633834, 'f1-score': 0.9879167941266441, 'support': 6467}, '1': {'precision': 0.7142857142857143, 'recall': 0.11764705882352941, 'f1-score': 0.20202020202020202, 'support': 170}, 'accuracy': 0.9761940635829441, 'macro avg': {'precision': 0.845794695545036, 'recall': 0.5582050045934563, 'f1-score': 0.5949684980734231, 'support': 6637}, 'weighted avg': {'precision': 0.9705667393886324, 'recall': 0.9761940635829441, 'f1-score': 0.9677868527889772, 'support': 6637}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Results:\")\n",
    "print(eval_model(device, lora_model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:39:39.547980Z",
     "iopub.status.busy": "2025-01-24T17:39:39.547579Z",
     "iopub.status.idle": "2025-01-24T17:39:56.634461Z",
     "shell.execute_reply": "2025-01-24T17:39:56.633602Z",
     "shell.execute_reply.started": "2025-01-24T17:39:39.547950Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>▇▅▁██▁▅▃▁▃▁▁▄▃▁▂▁▁▄▇▂▃▆▂▆▁▃▂▁▁▁▂█▁▁▁▁▁▆▇</td></tr><tr><td>epoch_train_loss</td><td>█▃▂▁</td></tr><tr><td>eval_accuracy</td><td>▁</td></tr><tr><td>eval_f1_macro</td><td>▁</td></tr><tr><td>eval_f1_weighted</td><td>▁</td></tr><tr><td>eval_precision_macro</td><td>▁</td></tr><tr><td>eval_precision_weighted</td><td>▁</td></tr><tr><td>eval_recall_macro</td><td>▁</td></tr><tr><td>eval_recall_weighted</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.02401</td></tr><tr><td>epoch_train_loss</td><td>0.13778</td></tr><tr><td>eval_accuracy</td><td>0.97619</td></tr><tr><td>eval_f1_macro</td><td>0.59497</td></tr><tr><td>eval_f1_weighted</td><td>0.96779</td></tr><tr><td>eval_precision_macro</td><td>0.84579</td></tr><tr><td>eval_precision_weighted</td><td>0.97057</td></tr><tr><td>eval_recall_macro</td><td>0.55821</td></tr><tr><td>eval_recall_weighted</td><td>0.97619</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">decent-frost-3</strong> at: <a href='https://wandb.ai/ankittriescoding-indian-institute-of-technology-kharagpur/lora-bert-finetune/runs/rnld8plc' target=\"_blank\">https://wandb.ai/ankittriescoding-indian-institute-of-technology-kharagpur/lora-bert-finetune/runs/rnld8plc</a><br> View project at: <a href='https://wandb.ai/ankittriescoding-indian-institute-of-technology-kharagpur/lora-bert-finetune' target=\"_blank\">https://wandb.ai/ankittriescoding-indian-institute-of-technology-kharagpur/lora-bert-finetune</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 14 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250124_155009-rnld8plc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:44:19.827914Z",
     "iopub.status.busy": "2025-01-24T17:44:19.827561Z",
     "iopub.status.idle": "2025-01-24T17:47:15.804249Z",
     "shell.execute_reply": "2025-01-24T17:47:15.803460Z",
     "shell.execute_reply.started": "2025-01-24T17:44:19.827887Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/all_set.zip'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive('all_set', 'zip', '/kaggle/working/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:47:20.419751Z",
     "iopub.status.busy": "2025-01-24T17:47:20.419463Z",
     "iopub.status.idle": "2025-01-24T17:47:20.424754Z",
     "shell.execute_reply": "2025-01-24T17:47:20.423979Z",
     "shell.execute_reply.started": "2025-01-24T17:47:20.419729Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='all_set.zip' target='_blank'>all_set.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/all_set.zip"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'all_set.zip')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6540708,
     "sourceId": 10570084,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "torch_trfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
